---
title: "Lab 15 - Bagging, Random Forests, and Boosting"
author: Tejas Dhomne
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: simplex
    number_sections: false
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
knitr::knit_meta(clean=T)
```

## 0 load the packages 
```{r}
library(gains)
library(caret)
library(adabag)
library(randomForest)

```

## 1 create a data frame
```{r}
# load the data and set stringsAsFactors to TRUE
ebay.df <-read.csv("eBayAuctions.csv", stringsAsFactors = TRUE)
# first six rows 
head(ebay.df)
# column names
names(ebay.df)
```

## 2 convert numeric variables to categorical variables
```{r}
# convert Duration to a categorical variable
ebay.df$Duration <- as.factor(ebay.df$Duration)
# convert Competitive. to a categorical variable
ebay.df$Competitive. <- as.factor(ebay.df$Competitive.)
# return the structure 
str(ebay.df)
```

## 3 data partition
```{r}
# set the seed 
set.seed(1)
# row numbers of the training set
train.index <- sample(c(1:dim(ebay.df)[1]), dim(ebay.df)[1]*0.6)
# training set 
train.df <- ebay.df[train.index, ]
# test set 
test.df <- ebay.df[-train.index, ]
```

## 4 bagging 

### 4.1 fit a bagging algorithm 
```{r}
set.seed(1)
bag <- bagging(Competitive. ~ ., data = train.df, mfinal=10)
```

### 4.2 make predictions for records in the test set  
```{r}
# predictions from a fitted bagging object 
bag.pred <- predict(bag, test.df)
# predicted probabilities 
head(bag.pred$prob)
# predicted classes
head(bag.pred$class)
```

### 4.3 create a confusion matrix 
```{r}
confusionMatrix(as.factor(bag.pred$class), test.df$Competitive., positive = "1")

```

## 5 random forests 

### 5.1 fit a random forests algorithm 
```{r}
set.seed(1)
rf <- randomForest(Competitive. ~ ., data = train.df, mtry = 4, ntree=10) 

```

### 5.2 variable importance plot
```{r}
varImpPlot(rf)

```

### 5.3 make predictions for records in the test set
```{r}
# predicted probabilities 
rf.pred.prob <- predict(rf, test.df, type="prob")
head(rf.pred.prob)
# predicted classes
rf.pred.class <- predict(rf, test.df, type="class")
head(rf.pred.class)
```

### 5.4 create a confusion matrix 
```{r}
confusionMatrix(rf.pred.class, test.df$Competitive., positive = "1")

```

### 5.5 create a gain table  
```{r}
# gain table 
gain <- gains(as.numeric(as.character(test.df$Competitive.)), rf.pred.prob[,2], groups = 10)
# cumulative percentage of competitive auctions 
gain$cume.pct.of.total
# cumulative number of auctions 
gain$cume.obs
```

### 5.6 plot a lift chart 
```{r}
# plot the cumulative number of competitive auctions against the cumulative number of auctions
plot(c(0,gain$cume.pct.of.total*sum(test.df$Competitive.==1))~c(0,gain$cume.obs), xlab="Cumulative number of auctions", ylab="Cumulative number of  competitive auctions", type="l")
# add a baseline curve 
lines(c(0,sum(test.df$Competitive.==1))~c(0, dim(test.df)[1]))
```

## 6 AdaBoost 

### 6.1 fit an adaptive boosting algorithm 
```{r}
set.seed(1)
boost <- boosting(Competitive. ~ ., data = train.df, mfinal=10)

```

### 6.2 make predictions for records in the test set  
```{r}
# predictions from a fitted bagging object 
boost.pred <- predict(boost, test.df)
# predicted probabilities 
boost.pred$prob 
# predicted classes 
boost.pred$class
```

### 6.3 create a confusion matrix 
```{r}
confusionMatrix(as.factor(boost.pred$class), test.df$Competitive.)

```
